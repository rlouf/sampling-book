
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Sparse regression &#8212; The Sampling Book Project</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Bayesian Logistic Regression" href="logistic_regression.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">The Sampling Book Project</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    The Sampling Book Project
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../algorithms/cyclical_sgld.html">
   Cyclical SGLD
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../algorithms/contour_sgld.html">
   Contour stochastic gradient Langevin dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../algorithms/pathfinder.html">
   Pathfinder
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Models
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="mlp.html">
   MLP classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hierarchical_bnn.html">
   Hierarchical Bayesian Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic_regression.html">
   Bayesian Logistic Regression
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Sparse regression
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/blackjax-devs/sampling-book/main?urlpath=tree/models/sparse_regression.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/blackjax-devs/sampling-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/blackjax-devs/sampling-book/issues/new?title=Issue%20on%20page%20%2Fmodels/sparse_regression.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/models/sparse_regression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../_sources/models/sparse_regression.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#german-credit-dataset">
   German credit dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#meads">
     MEADS
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliography">
   Bibliography
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Sparse regression</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#german-credit-dataset">
   German credit dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#meads">
     MEADS
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliography">
   Bibliography
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="sparse-regression">
<h1>Sparse regression<a class="headerlink" href="#sparse-regression" title="Permalink to this headline">#</a></h1>
<p>In this example we will use a sparse binary regression with hierarchies on the scale of the independent variable’s parameters that function as a proxy for variable selection. We will use the Horseshoe prior to <span id="id1">[<a class="reference internal" href="#id8" title="Carlos M Carvalho, Nicholas G Polson, and James G Scott. The horseshoe estimator for sparse signals. Biometrika, 97(2):465–480, 2010.">CPS10</a>]</span> to ensure sparsity.</p>
<p>The Horseshoe prior consists in putting a prior on the scale of the regression parameter <span class="math notranslate nohighlight">\(\beta\)</span>: the product of a global <span class="math notranslate nohighlight">\(\tau\)</span> and local <span class="math notranslate nohighlight">\(\lambda\)</span> parameter that are both concentrated at <span class="math notranslate nohighlight">\(0\)</span>, thus allowing the corresponding regression parameter to degenerate at <span class="math notranslate nohighlight">\(0\)</span> and effectively excluding this parameter from the model. This kind of model is challenging for samplers: the prior on <span class="math notranslate nohighlight">\(\beta\)</span>’s scale parameter creates funnel geometries that are hard to efficiently explore <span id="id2">[<a class="reference internal" href="#id14" title="Omiros Papaspiliopoulos, Gareth O Roberts, and Martin Sköld. A general framework for the parametrization of hierarchical models. Statistical Science, pages 59–73, 2007.">PRSkold07</a>]</span>.</p>
<p>Mathematically, we will consider the following model:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\tau &amp;\sim \operatorname{C}^+(0, 1)\\
\boldsymbol{\lambda} &amp;\sim \operatorname{C}^+(0, 1)\\
\boldsymbol{\beta} &amp;\sim \operatorname{Normal}(0, \tau \lambda)\\
\\
p &amp;= \operatorname{sigmoid}\left(- X.\boldsymbol{\beta}\right)\\
y &amp;\sim \operatorname{Bernoulli}(p)\\
\end{align*}\]</div>
<p>The model is run on its <em>non-centered parametrization</em> <span id="id3">[<a class="reference internal" href="#id14" title="Omiros Papaspiliopoulos, Gareth O Roberts, and Martin Sköld. A general framework for the parametrization of hierarchical models. Statistical Science, pages 59–73, 2007.">PRSkold07</a>]</span> with data from the numerical version of the German credit dataset. The target posterior is defined by its likelihood. We implement the model using <a class="reference external" href="https://github.com/aesara-devs/aesara">Aesara</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">aesara.tensor</span> <span class="k">as</span> <span class="nn">at</span>

<span class="n">X_at</span> <span class="o">=</span> <span class="n">at</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>

<span class="n">srng</span> <span class="o">=</span> <span class="n">at</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomStream</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">tau_rv</span> <span class="o">=</span> <span class="n">srng</span><span class="o">.</span><span class="n">halfcauchy</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">lambda_rv</span> <span class="o">=</span> <span class="n">srng</span><span class="o">.</span><span class="n">halfcauchy</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">X_at</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">sigma</span> <span class="o">=</span> <span class="n">tau_rv</span> <span class="o">*</span> <span class="n">lambda_rv</span>
<span class="n">beta_rv</span> <span class="o">=</span> <span class="n">srng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">X_at</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">eta</span> <span class="o">=</span> <span class="n">X_at</span> <span class="o">@</span> <span class="n">beta_rv</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">at</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="o">-</span><span class="n">eta</span><span class="p">)</span>
<span class="n">Y_rv</span> <span class="o">=</span> <span class="n">srng</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The non-centered parametrization is not necessarily adapted to every geometry. One should always check <em>a posteriori</em> the sampler did not encounter any funnel geomtry.</p>
</div>
<section id="german-credit-dataset">
<h2>German credit dataset<a class="headerlink" href="#german-credit-dataset" title="Permalink to this headline">#</a></h2>
<p>We will use the sparse regression model on the German credit dataset <span id="id4">[<a class="reference internal" href="#id9" title="Dheeru Dua and Casey Graff. UCI machine learning repository. 2017. URL: http://archive.ics.uci.edu/ml.">DG17</a>]</span>. We use the numeric version that is adapted to models that cannot handle categorical data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span>
  <span class="s2">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric&quot;</span><span class="p">,</span>
  <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">delim_whitespace</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Each row in the dataset corresponds to a different customer. The dependent variable <span class="math notranslate nohighlight">\(y\)</span> is equal to <span class="math notranslate nohighlight">\(1\)</span> when the customer has good credit and <span class="math notranslate nohighlight">\(2\)</span> when it has bad credit; we encode it so a customer with good credit corresponds to <span class="math notranslate nohighlight">\(1\)</span>, a customer with bad credit <span class="math notranslate nohighlight">\(1\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r_bad</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mf">0.</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">r_good</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span>  <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r_bad</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s2">% of the customers in the dataset are classified as having bad credit.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>30.0% of the customers in the dataset are classified as having bad credit.
</pre></div>
</div>
</div>
</div>
<p>The regressors are defined on different scales so we normalize their values, and add a column of <span class="math notranslate nohighlight">\(1\)</span> that corresponds to the intercept:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="o">.</span><span class="n">values</span>
<span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">#</a></h2>
<p>We generate a function that computes the model’s logdensity using <a class="reference external" href="https://github.com/aesara-devs/aeppl">AePPL</a>. We transform the values of <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span> so the sampler can operate on variables defined on the real line:</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">aesara</span>
<span class="kn">import</span> <span class="nn">aeppl</span>
<span class="kn">from</span> <span class="nn">aeppl.transforms</span> <span class="kn">import</span> <span class="n">TransformValuesRewrite</span><span class="p">,</span> <span class="n">LogTransform</span>

<span class="n">transforms_op</span> <span class="o">=</span> <span class="n">TransformValuesRewrite</span><span class="p">(</span>
     <span class="p">{</span><span class="n">lambda_rv</span><span class="p">:</span> <span class="n">LogTransform</span><span class="p">(),</span> <span class="n">tau_rv</span><span class="p">:</span> <span class="n">LogTransform</span><span class="p">()}</span>
<span class="p">)</span>

<span class="n">logdensity</span><span class="p">,</span> <span class="n">value_variables</span> <span class="o">=</span> <span class="n">aeppl</span><span class="o">.</span><span class="n">joint_logprob</span><span class="p">(</span>
    <span class="n">tau_rv</span><span class="p">,</span>
    <span class="n">lambda_rv</span><span class="p">,</span>
    <span class="n">beta_rv</span><span class="p">,</span>
    <span class="n">realized</span><span class="o">=</span><span class="p">{</span><span class="n">Y_rv</span><span class="p">:</span> <span class="n">at</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)},</span>
    <span class="n">extra_rewrites</span><span class="o">=</span><span class="n">transforms_op</span>
<span class="p">)</span>


<span class="n">logdensity_aesara_fn</span> <span class="o">=</span> <span class="n">aesara</span><span class="o">.</span><span class="n">function</span><span class="p">([</span><span class="n">X_at</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">value_variables</span><span class="p">),</span> <span class="n">logdensity</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;JAX&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">logdensity_fn</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;log_tau&#39;</span><span class="p">]</span>
    <span class="n">lmbda</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;log_lmbda&#39;</span><span class="p">]</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">logdensity_aesara_fn</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">jit_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">lmbda</span><span class="p">,</span> <span class="n">beta</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let us now define a utility function that builds a sampling loop:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>

<span class="k">def</span> <span class="nf">inference_loop</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">init_state</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">init_state</span><span class="p">,</span> <span class="n">keys</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">info</span>
</pre></div>
</div>
</div>
</div>
<section id="meads">
<h3>MEADS<a class="headerlink" href="#meads" title="Permalink to this headline">#</a></h3>
<p>The MEADS algorithm <span id="id5">[<a class="reference internal" href="#id10" title="Matthew D Hoffman and Pavel Sountsov. Tuning-free generalized hamiltonian monte carlo. In International Conference on Artificial Intelligence and Statistics, 7799–7813. PMLR, 2022.">HS22</a>]</span> is a combination of Generalized HMC with a parameter tuning procedure. Let us initialize the position of the chain first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_chains</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_warmup</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">2000</span>

<span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">rng_key</span><span class="p">,</span> <span class="n">key_b</span><span class="p">,</span> <span class="n">key_l</span><span class="p">,</span> <span class="n">key_t</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">init_position</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key_b</span><span class="p">,</span> <span class="p">(</span><span class="n">num_chains</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span>
    <span class="s2">&quot;log_lmbda&quot;</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key_l</span><span class="p">,</span> <span class="p">(</span><span class="n">num_chains</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span>
    <span class="s2">&quot;log_tau&quot;</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key_t</span><span class="p">,</span> <span class="p">(</span><span class="n">num_chains</span><span class="p">,)),</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Here we will not use the adaptive version of the MEADS algorithm, but instead use their heuristics as an adaptation procedure for Generalized Hamiltonian Monte Carlo kernels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">blackjax</span>

<span class="n">key_warmup</span><span class="p">,</span> <span class="n">key_sample</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
<span class="n">meads</span> <span class="o">=</span> <span class="n">blackjax</span><span class="o">.</span><span class="n">meads_adaptation</span><span class="p">(</span><span class="n">logdensity_fn</span><span class="p">,</span> <span class="n">num_chains</span><span class="p">)</span>
<span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">parameters</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">meads</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">key_warmup</span><span class="p">,</span> <span class="n">init_position</span><span class="p">,</span> <span class="n">num_warmup</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">blackjax</span><span class="o">.</span><span class="n">ghmc</span><span class="p">(</span><span class="n">logdensity_fn</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">)</span><span class="o">.</span><span class="n">step</span>

<span class="c1"># Choose the last state of the first two chains as a starting point for the sampler</span>
<span class="n">init_states</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">state</span><span class="p">)</span>
<span class="n">keys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">inference_loop</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">))(</span><span class="n">keys</span><span class="p">,</span> <span class="n">init_states</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us look a high-level summary statistics for the inference, including the split-Rhat value and the number of effective samples:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpyro.diagnostics</span> <span class="kn">import</span> <span class="n">print_summary</span>

<span class="n">print_summary</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">position</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   mean       std    median      5.0%     95.0%     n_eff     r_hat
      beta[0]     -0.26      0.33     -0.19     -0.74      0.22     45.94      1.06
      beta[1]     -0.81      0.12     -0.80     -1.02     -0.64     74.73      1.01
      beta[2]      1.21      0.28      1.22      0.74      1.64     74.57      1.01
      beta[3]     -0.71      0.17     -0.73     -1.00     -0.44     92.76      1.06
      beta[4]      0.20      0.28      0.15     -0.19      0.62     36.80      1.00
      beta[5]     -0.41      0.13     -0.41     -0.60     -0.20     63.17      1.01
      beta[6]     -0.20      0.14     -0.19     -0.40      0.02     61.47      1.01
      beta[7]     -0.22      0.16     -0.21     -0.50      0.03     54.92      1.02
      beta[8]      0.01      0.08      0.00     -0.10      0.15     83.01      1.00
      beta[9]      0.19      0.14      0.19     -0.03      0.41     69.27      1.02
     beta[10]     -0.13      0.18     -0.09     -0.47      0.11     29.33      1.01
     beta[11]     -0.28      0.11     -0.28     -0.46     -0.12     86.92      1.01
     beta[12]      0.22      0.22      0.19     -0.12      0.53     59.19      1.05
     beta[13]      0.01      0.09      0.00     -0.15      0.14     52.17      1.02
     beta[14]     -0.07      0.07     -0.06     -0.17      0.05     84.17      1.04
     beta[15]     -0.40      0.26     -0.42     -0.80      0.03     58.62      1.01
     beta[16]      0.29      0.10      0.28      0.14      0.45     68.68      1.03
     beta[17]     -0.35      0.16     -0.35     -0.63     -0.10     96.87      1.01
     beta[18]      0.23      0.18      0.21     -0.04      0.50     47.77      1.01
     beta[19]      0.33      0.24      0.32     -0.06      0.68     44.98      1.02
     beta[20]      0.15      0.13      0.14     -0.05      0.34     29.72      1.02
     beta[21]     -0.06      0.10     -0.05     -0.24      0.10     42.68      1.02
     beta[22]     -0.04      0.16     -0.02     -0.36      0.20     56.69      1.02
     beta[23]     -0.01      0.07     -0.00     -0.11      0.10     44.42      1.03
     beta[24]      0.00      0.05      0.00     -0.09      0.10    116.34      1.00
 log_lmbda[0]     -0.02      1.23      0.03     -2.19      1.93     42.31      1.04
 log_lmbda[1]      1.10      0.71      1.00      0.02      2.25      8.97      1.12
 log_lmbda[2]      1.33      0.74      1.21      0.21      2.37     61.13      1.04
 log_lmbda[3]      1.01      0.90      0.87     -0.37      2.39     52.88      1.08
 log_lmbda[4]     -0.16      1.02     -0.13     -1.73      1.58     62.53      1.00
 log_lmbda[5]      0.47      0.77      0.35     -0.66      1.73     53.89      1.06
 log_lmbda[6]     -0.11      1.07     -0.12     -2.00      1.31     43.00      1.02
 log_lmbda[7]      0.03      1.06      0.01     -1.61      1.94     64.74      1.03
 log_lmbda[8]     -0.92      1.17     -0.87     -2.96      0.81     34.93      1.08
 log_lmbda[9]      0.13      1.23      0.08     -1.91      2.08     63.26      1.05
log_lmbda[10]     -0.39      1.04     -0.24     -2.24      1.18     40.20      1.03
log_lmbda[11]      0.22      0.82      0.20     -1.20      1.38     56.60      1.05
log_lmbda[12]     -0.09      1.12     -0.03     -1.85      1.75     60.54      1.05
log_lmbda[13]     -0.85      1.21     -0.79     -2.95      0.98     58.09      1.02
log_lmbda[14]     -0.99      1.07     -0.89     -3.04      0.53     69.20      1.05
log_lmbda[15]      0.37      1.06      0.45     -1.18      2.39     65.36      1.01
log_lmbda[16]      0.34      0.86      0.19     -0.95      1.82     71.62      1.01
log_lmbda[17]      0.33      0.74      0.25     -0.70      1.70     83.19      1.01
log_lmbda[18]     -0.05      0.95      0.02     -1.37      1.72     83.48      1.02
log_lmbda[19]      0.15      0.97      0.26     -1.44      1.66     35.19      1.07
log_lmbda[20]     -0.42      1.03     -0.35     -2.04      1.21     24.23      1.08
log_lmbda[21]     -0.69      1.01     -0.66     -2.17      0.98     99.62      1.03
log_lmbda[22]     -0.51      1.11     -0.53     -2.34      1.15     55.27      1.05
log_lmbda[23]     -0.97      1.09     -0.95     -2.52      0.94     89.31      1.04
log_lmbda[24]     -1.34      1.32     -1.17     -3.60      0.77     57.58      1.00
      log_tau     -1.25      0.34     -1.25     -1.84     -0.76     21.03      1.09
</pre></div>
</div>
</div>
</div>
<p>Let’s check if there are any divergent transitions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">info</span><span class="o">.</span><span class="n">is_divergent</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([0, 0], dtype=int64)
</pre></div>
</div>
</div>
</div>
<p>We warned earlier that the non-centered parametrization was not a one-size-fits-all solution to the funnel geometries that can be present in the posterior distribution. Although there was no divergence, it is still worth checking the posterior interactions between the coefficients to make sure the posterior geometry did not get in the way of sampling:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pylab</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">import</span> <span class="nn">matplotlib.gridspec</span> <span class="k">as</span> <span class="nn">gridspec</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gaussian_kde</span>

<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="k">10</span>, i//10])
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="s2">&quot;log_lmbda&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,:,</span><span class="n">i</span><span class="p">],</span> <span class="n">samples</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,:,</span><span class="n">i</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">rf</span><span class="s2">&quot;$\lambda$[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">rf</span><span class="s2">&quot;$\beta$[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;top&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/sparse_regression_22_0.png" src="../_images/sparse_regression_22_0.png" />
</div>
</div>
<p>While some parameters (for instance the 15th) exhibit no particular correlations, the funnel geometry can still be observed for a few of them (4th, 13th, etc.). Ideally one would adopt a centered parametrization for those parameters to get a better approximation to the true posterior distribution, but here we also assess the ability of the sampler to explore these funnel geometries.</p>
<p>We can convince ourselves that the Horseshoe prior induces sparsity on the regression coefficients by looking at their posterior distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pylab</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.gridspec</span> <span class="k">as</span> <span class="nn">gridspec</span>

<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="k">10</span>, i//10])
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">rf</span><span class="s2">&quot;$\beta$[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;top&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">get_yaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/sparse_regression_25_0.png" src="../_images/sparse_regression_25_0.png" />
</div>
</div>
<p>Indeed, many of the parameters are centered around <span class="math notranslate nohighlight">\(0\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is interesting to notice that the interactions for the parameters with large values do not exhibit funnel geometries.</p>
</div>
</section>
</section>
<section id="bibliography">
<h2>Bibliography<a class="headerlink" href="#bibliography" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id6">
<dl class="citation">
<dt class="label" id="id8"><span class="brackets"><a class="fn-backref" href="#id1">CPS10</a></span></dt>
<dd><p>Carlos M Carvalho, Nicholas G Polson, and James G Scott. The horseshoe estimator for sparse signals. <em>Biometrika</em>, 97(2):465–480, 2010.</p>
</dd>
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id4">DG17</a></span></dt>
<dd><p>Dheeru Dua and Casey Graff. UCI machine learning repository. 2017. URL: <a class="reference external" href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>.</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id5">HS22</a></span></dt>
<dd><p>Matthew D Hoffman and Pavel Sountsov. Tuning-free generalized hamiltonian monte carlo. In <em>International Conference on Artificial Intelligence and Statistics</em>, 7799–7813. PMLR, 2022.</p>
</dd>
<dt class="label" id="id14"><span class="brackets">PRSkold07</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id3">2</a>)</span></dt>
<dd><p>Omiros Papaspiliopoulos, Gareth O Roberts, and Martin Sköld. A general framework for the parametrization of hierarchical models. <em>Statistical Science</em>, pages 59–73, 2007.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="logistic_regression.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Bayesian Logistic Regression</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Blackjax Team<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>